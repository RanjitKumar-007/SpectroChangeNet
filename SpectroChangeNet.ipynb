{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7388,
     "status": "ok",
     "timestamp": 1725381235922,
     "user": {
      "displayName": "ranjith nandha",
      "userId": "16794777534270669263"
     },
     "user_tz": -330
    },
    "id": "mTuKqq3faUl2"
   },
   "outputs": [],
   "source": [
    "\"\"\"Importing libraries\"\"\"\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "from scipy import signal\n",
    "from scipy.linalg import norm\n",
    "from scipy.spatial.distance import cdist\n",
    "import skimage\n",
    "from skimage import io, measure\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from collections import  Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Checking GPU avilability\"\"\"\n",
    "import torch \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 442,
     "status": "ok",
     "timestamp": 1725381240683,
     "user": {
      "displayName": "ranjith nandha",
      "userId": "16794777534270669263"
     },
     "user_tz": -330
    },
    "id": "cgxZU8t7aGbA"
   },
   "outputs": [],
   "source": [
    "def del2(im):\n",
    "    \"\"\"del2 (discrete laplacian operator)\"\"\"\n",
    "    [ylen, xlen] = im.shape\n",
    "    im_new = np.zeros([ylen, xlen], dtype=np.float32)\n",
    "    for j in range(1, ylen-1):\n",
    "        for i in range(1, xlen-1):\n",
    "            im_new[j,i] = (im[j-1,i]+im[j+1,i]+im[j,i-1]+im[j,i+1])/4-im[j,i]\n",
    "    return im_new\n",
    "def srad(im, delta):\n",
    "    \"\"\"srad (speckle reducing anisotropic diffusion)\"\"\"\n",
    "    q0 = 1\n",
    "    for n in range(1, 6):\n",
    "        [ylen, xlen] = im.shape\n",
    "        X = np.zeros([ylen+2, xlen+2], dtype=np.float32)\n",
    "        X[1:ylen+1, 1:xlen+1] = im\n",
    "        #padding\n",
    "        X[0, 1:xlen+1] = im[0, :]\n",
    "        X[ylen+1, 1:xlen+1] = im[ylen-1, :]\n",
    "        X[:, 0] = X[:, 1]\n",
    "        X[:, xlen+1] = X[:, xlen]\n",
    "        q0 = q0*np.exp(-delta)\n",
    "        gRx = signal.convolve2d(X, [[0,0,0],[0,1,-1],[0,0,0]], mode='same', boundary='symm')\n",
    "        gRy = signal.convolve2d(X, [[0,-1,0],[0,1,0],[0,0,0]], mode='same', boundary='symm')\n",
    "        gLx = signal.convolve2d(X, [[0,0,0],[1,-1,0],[0,0,0]], mode='same', boundary='symm')\n",
    "        gLy = signal.convolve2d(X, [[0,0,0],[0,-1,0],[0,1,0]], mode='same', boundary='symm')\n",
    "        q1 = np.sqrt(gRx*gRx+gRy*gRy+gLx*gLx+gLy*gLy)/(X+0.0001)\n",
    "        q2 = 4*del2(X)/(X+0.0001)\n",
    "        q = np.sqrt(np.maximum(0, (1/2*(q1*q1)-1/16*(q2*q2))/((1+1/4*q2)*(1+1/4*q2)+0.01)))\n",
    "        c = 1/(1+((q*q-q0*q0)/(q0*q0*(1+q0*q0))))\n",
    "        d = signal.convolve2d(c, [[0,0,0],[0,0,-1],[0,0,0]],  mode='same', boundary='symm')* \\\n",
    "            signal.convolve2d(X, [[0,0,0],[0,1,-1],[0,0,0]], mode='same', boundary='symm')+ \\\n",
    "            signal.convolve2d(c, [[0,0,0],[0,-1,0],[0,0,0]],  mode='same', boundary='symm')* \\\n",
    "            signal.convolve2d(X, [[0,0,0],[-1,1,0],[0,0,0]], mode='same', boundary='symm')+ \\\n",
    "            signal.convolve2d(c, [[0,-1,0],[0,0,0],[0,0,0]],  mode='same', boundary='symm')* \\\n",
    "            signal.convolve2d(X, [[0,-1,0],[0,1,0],[0,0,0]], mode='same', boundary='symm')+ \\\n",
    "            signal.convolve2d(c, [[0,0,0],[0,-1,0],[0,0,0]],  mode='same', boundary='symm')* \\\n",
    "            signal.convolve2d(X, [[0,0,0],[0,1,0],[0,-1,0]], mode='same', boundary='symm')\n",
    "        X = X+delta/4*d\n",
    "        im = X[1:ylen+1, 1:xlen+1]\n",
    "    return im\n",
    "def dicomp(im1, im2):\n",
    "    \"\"\"dicomp (dictionary learning and sparse coding)\"\"\"\n",
    "    im1 = srad(im1, 0.15)\n",
    "    im2 = srad(im2, 0.15)\n",
    "    im_di = abs(np.log((im1+1)/(im2+1)))\n",
    "    im_di = srad(im_di, 0.15)\n",
    "    return im_di\n",
    "def hcluster(pix_vec, im_di):\n",
    "    \"\"\"hcluster (hierarchical clustering)\"\"\"\n",
    "    fcm = FCM(n_clusters=2)\n",
    "    fcm.fit(pix_vec)\n",
    "    fcm_lab = fcm.u.argmax(axis=1)\n",
    "    if sum(fcm_lab==0)<sum(fcm_lab==1):\n",
    "        ttr = round(sum(fcm_lab==0)*1.25)\n",
    "        ttl = round(sum(fcm_lab==0)/1.10)\n",
    "    else:\n",
    "        ttr = round(sum(fcm_lab==1)*1.25)\n",
    "        ttl = round(sum(fcm_lab==1)/1.10)\n",
    "    fcm = FCM(n_clusters=5)\n",
    "    fcm.fit(pix_vec)\n",
    "    fcm_lab  = fcm.u.argmax(axis=1)\n",
    "    ylen, xlen = im_di.shape\n",
    "    idx = []\n",
    "    idx_tmp = []\n",
    "    idxmean = []\n",
    "    res_lab = np.zeros(ylen*xlen, dtype=np.float32)\n",
    "    for i in range(0, 5):\n",
    "        idx_tmp.append(np.argwhere(fcm_lab==i))\n",
    "        idxmean.append(im_di.reshape(ylen*xlen, 1)[idx_tmp[i]].mean())\n",
    "    idx_sort = np.argsort(idxmean)\n",
    "    for i in range(0, 5):\n",
    "        idx.append(idx_tmp[idx_sort[i]])\n",
    "    c = len(idx[4])\n",
    "    res_lab[idx[4]] = 2\n",
    "    flag_mid = 0\n",
    "    for i in range(1, 5):\n",
    "        c = c+len(idx[4-i])\n",
    "        if c < ttl:\n",
    "            res_lab[idx[4-i]] = 2\n",
    "        elif c >= ttl and c < ttr:\n",
    "            res_lab[idx[4-i]] = 1.5\n",
    "            flag_mid = 1\n",
    "        elif flag_mid == 0:\n",
    "            res_lab[idx[4-i]] = 1.5\n",
    "            flag_mid = 1\n",
    "        else:\n",
    "            res_lab[idx[4-i]] = 1\n",
    "    res_lab = res_lab.reshape(ylen, xlen)\n",
    "    return res_lab\n",
    "class FCM:\n",
    "    \"\"\"Fuzzy C means\"\"\"\n",
    "    def __init__(self, n_clusters=10, max_iter=150, m=2, error=1e-5, random_state=42):\n",
    "        self.u, self.centers = None, None\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.m = m\n",
    "        self.error = error\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X):\n",
    "        N = X.shape[0]\n",
    "        C = self.n_clusters\n",
    "        centers = []\n",
    "        r = np.random.RandomState(self.random_state)\n",
    "        u = r.rand(N,C)\n",
    "        u = u / np.tile(u.sum(axis=1)[np.newaxis].T,C)\n",
    "        iteration = 0\n",
    "        while iteration < self.max_iter:\n",
    "            u2 = u.copy()\n",
    "            centers = self.next_centers(X, u)\n",
    "            u = self.next_u(X, centers)\n",
    "            iteration += 1\n",
    "            #Stopping rule\n",
    "            if norm(u - u2) < self.error:\n",
    "                break\n",
    "        self.u = u\n",
    "        self.centers = centers\n",
    "        return self\n",
    "    def next_centers(self, X, u):\n",
    "        um = u ** self.m\n",
    "        return (X.T @ um / np.sum(um, axis=0)).T\n",
    "    def next_u(self, X, centers):\n",
    "        return self._predict(X, centers)\n",
    "    def _predict(self, X, centers):\n",
    "        power = float(2 / (self.m - 1))\n",
    "        temp = cdist(X, centers) ** power\n",
    "        denominator_ = temp.reshape((X.shape[0], 1, -1)).repeat(temp.shape[-1], axis=1)\n",
    "        denominator_ = temp[:, :, np.newaxis] / denominator_\n",
    "        return 1 / denominator_.sum(2)\n",
    "    def predict(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        u = self._predict(X, self.centers)\n",
    "        return np.argmax(u, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1725381247132,
     "user": {
      "displayName": "ranjith nandha",
      "userId": "16794777534270669263"
     },
     "user_tz": -330
    },
    "id": "QCg0_GWPT1wn",
    "outputId": "410f11d6-3433-4796-9be0-c015eecfe8a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 290, 3)\n",
      "(350, 290, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Reading input images\"\"\"\n",
    "image1 = cv2.imread('Ottawa_1.bmp')\n",
    "image2 = cv2.imread('Ottawa_2.bmp')\n",
    "\"\"\"Resizing image2 as like image1 (can be skipped if image size's are same)\"\"\"\n",
    "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n",
    "print(image1.shape)\n",
    "print(image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1725381251059,
     "user": {
      "displayName": "ranjith nandha",
      "userId": "16794777534270669263"
     },
     "user_tz": -330
    },
    "id": "PlIVXdXwmeH-"
   },
   "outputs": [],
   "source": [
    "def image_normalize(data):\n",
    "    \"\"\"Normalization\"\"\"\n",
    "    _mean = np.mean(data)\n",
    "    _std = np.std(data)\n",
    "    npixel = np.size(data) * 1.0\n",
    "    min_stddev = 1.0 / math.sqrt(npixel)\n",
    "    return (data - _mean) / max(_std, min_stddev)\n",
    "def image_padding(data,r):\n",
    "    \"\"\"Image padding\"\"\"\n",
    "    if len(data.shape)==3:\n",
    "        data_new=np.lib.pad(data,((r,r),(r,r),(0,0)),'constant',constant_values=0)\n",
    "        return data_new\n",
    "    if len(data.shape)==2:\n",
    "        data_new=np.lib.pad(data,r,'constant',constant_values=0)\n",
    "        return data_new\n",
    "def arr(length):\n",
    "  \"\"\"Array\"\"\"\n",
    "  arr=np.arange(length-1)\n",
    "  random.shuffle(arr)\n",
    "  print(arr)\n",
    "  return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1725381254293,
     "user": {
      "displayName": "ranjith nandha",
      "userId": "16794777534270669263"
     },
     "user_tz": -330
    },
    "id": "r0i8PdAGm7RE"
   },
   "outputs": [],
   "source": [
    "def createTrainingCubes(X, y, patch_size):\n",
    "    \"\"\"Creating training cubes\"\"\"\n",
    "    margin = int((patch_size - 1) / 2)\n",
    "    zeroPaddedX = image_padding(X, margin)\n",
    "    ele_num1 = np.sum(y==1)\n",
    "    ele_num2 = np.sum(y==2)\n",
    "    patchesData_1 = np.zeros( (ele_num1, patch_size, patch_size, X.shape[2]) )\n",
    "    patchesLabels_1 = np.zeros(ele_num1)\n",
    "    patchesData_2 = np.zeros((ele_num2, patch_size, patch_size, X.shape[2]))\n",
    "    patchesLabels_2 = np.zeros(ele_num2)\n",
    "    patchIndex_1 = 0\n",
    "    patchIndex_2 = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            if y[r-margin, c-margin] == 1 :\n",
    "                patch_1 = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
    "                patchesData_1[patchIndex_1, :, :, :] = patch_1\n",
    "                patchesLabels_1[patchIndex_1] = y[r-margin, c-margin]\n",
    "                patchIndex_1 = patchIndex_1 + 1\n",
    "            elif y[r-margin, c-margin] == 2 :\n",
    "                patch_2 = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
    "                patchesData_2[patchIndex_2, :, :, :] = patch_2\n",
    "                patchesLabels_2[patchIndex_2] = y[r-margin, c-margin]\n",
    "                patchIndex_2 = patchIndex_2 + 1\n",
    "    patchesLabels_1 = patchesLabels_1-1\n",
    "    patchesLabels_2 = patchesLabels_2-1\n",
    "    arr_1=arr(len(patchesData_1))\n",
    "    arr_2=arr(len(patchesData_2))\n",
    "    train_len=min(10000,len(patchesData_1) + len(patchesData_2))\n",
    "    pdata=np.zeros((train_len, patch_size, patch_size, X.shape[2]))\n",
    "    plabels = np.zeros(train_len)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for k in range(train_len):\n",
    "        if k < len(patchesData_1):\n",
    "            pdata[k,:,:,:]=patchesData_1[arr_1[i],:,:,:]\n",
    "            plabels[k]=patchesLabels_1[arr_1[i]]\n",
    "            i += 1\n",
    "        else:\n",
    "            pdata[k,:,:,:]=patchesData_2[arr_2[j],:,:,:]\n",
    "            plabels[k]=patchesLabels_2[arr_2[j]]\n",
    "            j += 1\n",
    "    return pdata, plabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1725381258564,
     "user": {
      "displayName": "ranjith nandha",
      "userId": "16794777534270669263"
     },
     "user_tz": -330
    },
    "id": "EMqKSmVZnDbX"
   },
   "outputs": [],
   "source": [
    "def createTestingCubes(X, patch_size):\n",
    "    \"\"\"Creating testing cubes\"\"\"\n",
    "    margin = int((patch_size - 1) / 2)\n",
    "    zeroPaddedX = image_padding(X, margin)\n",
    "    patchesData = np.zeros( (X.shape[0]*X.shape[1], patch_size, patch_size, X.shape[2]) )\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchIndex = patchIndex + 1\n",
    "    return patchesData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1725381259972,
     "user": {
      "displayName": "ranjith nandha",
      "userId": "16794777534270669263"
     },
     "user_tz": -330
    },
    "id": "cKObChKS3g0z"
   },
   "outputs": [],
   "source": [
    "def postprocess(res):\n",
    "    \"\"\"Post_processing\"\"\"\n",
    "    res_new = res\n",
    "    res = measure.label(res, connectivity=2)\n",
    "    num = res.max()\n",
    "    for i in range(1, num+1):\n",
    "        idy, idx = np.where(res==i)\n",
    "        if len(idy) <= 20:\n",
    "            res_new[idy, idx] = 0\n",
    "    return res_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21886,
     "status": "ok",
     "timestamp": 1725381285821,
     "user": {
      "displayName": "ranjith nandha",
      "userId": "16794777534270669263"
     },
     "user_tz": -330
    },
    "id": "cCDtrcf3oOIn",
    "outputId": "670fbda7-edb7-4142-db0c-8a437fc14248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiearchical clustering finished\n",
      "[44301 82674 22312 ... 73680 58428  6601]\n",
      "[1755 8598 4345 ...  895 2444 8663]\n",
      "x train shape:  (10000, 3, 7, 7)\n",
      "y train shape:  (10000,)\n",
      "x test shape:  (101500, 3, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Transforming images to float32\"\"\"\n",
    "im1 = image1[:, :, 0].astype(np.float32)\n",
    "im2 = image2[:, :, 0].astype(np.float32)\n",
    "im_di = dicomp(im1, im2)\n",
    "ylen, xlen = im_di.shape\n",
    "pix_vec = im_di.reshape([ylen*xlen, 1])\n",
    "preclassify_lab = hcluster(pix_vec, im_di)\n",
    "print('hiearchical clustering finished')\n",
    "mdata = np.zeros([im1.shape[0], im1.shape[1], 3], dtype=np.float32)\n",
    "mdata[:,:,0] = im1\n",
    "mdata[:,:,1] = im2\n",
    "mdata[:,:,2] = im_di\n",
    "mlabel = preclassify_lab\n",
    "x_train, y_train = createTrainingCubes(mdata, mlabel, patch_size)\n",
    "x_train = x_train.transpose(0, 3, 1, 2)\n",
    "print('x train shape: ', x_train.shape)\n",
    "print('y train shape: ', y_train.shape)\n",
    "x_test = createTestingCubes(mdata, patch_size)\n",
    "x_test = x_test.transpose(0, 3, 1, 2)\n",
    "print('x test shape: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "l-ZR_Qmyoq2_"
   },
   "outputs": [],
   "source": [
    "class TrainDS(torch.utils.data.Dataset):\n",
    "    \"\"\"Training dataset\"\"\"\n",
    "    def __init__(self):\n",
    "        self.len = x_train.shape[0]\n",
    "        self.x_data = torch.FloatTensor(x_train)\n",
    "        self.y_data = torch.LongTensor(y_train)\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "trainset = TrainDS()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=128, shuffle=True, num_workers=0)\n",
    "class MRC(nn.Module):\n",
    "    \"\"\"Multi-region convolution\"\"\"\n",
    "    def __init__(self, inchannel):\n",
    "        super(MRC, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inchannel, 15, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(15)\n",
    "        self.conv2_1 = nn.Conv2d(5, 5, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.bn2_1 = nn.BatchNorm2d(5)\n",
    "        self.conv2_2 = nn.Conv2d(5, 5, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.bn2_2 = nn.BatchNorm2d(5)\n",
    "        self.conv2_3 = nn.Conv2d(5, 5, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.bn2_3 = nn.BatchNorm2d(5)\n",
    "    def forward(self, x):\n",
    "       ori_out = F.relu(self.bn1(self.conv1(x)))\n",
    "       shape=(x.shape[0], 5, 7, 7)\n",
    "       all_zero3_3=torch.zeros(size=shape).cuda()\n",
    "       all_zero1_3=torch.zeros(size=(x.shape[0], 5, 3, 7)).cuda()\n",
    "       all_zero3_1=torch.zeros(size=(x.shape[0], 5, 7, 3)).cuda()\n",
    "       all_zero3_3[:,:,:,:]=ori_out[:,0:5,:,:]\n",
    "       all_zero1_3[:,:,:,:]=ori_out[:,5:10,2:5,:]\n",
    "       all_zero3_1[:,:,:,:]=ori_out[:,10:15,:,2:5]\n",
    "       square=F.relu(self.bn2_1(self.conv2_1(all_zero3_3)))\n",
    "       horizontal=F.relu(self.bn2_2(self.conv2_2(all_zero1_3)))\n",
    "       vertical=F.relu(self.bn2_3(self.conv2_3(all_zero3_1)))\n",
    "       horizontal_final=torch.zeros(size=(x.shape[0], 5, 7, 7)).cuda()\n",
    "       vertical_final=torch.zeros(size=(x.shape[0], 5, 7, 7)).cuda()\n",
    "       horizontal_final[:,:,2:5,:]=horizontal[:,:,:,:]\n",
    "       vertical_final[:,:,:,2:5]=vertical[:,:,:,:]\n",
    "       glo = square + horizontal_final + vertical_final\n",
    "       return glo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "iI2c6Do3o4sH"
   },
   "outputs": [],
   "source": [
    "def DCT(x):\n",
    "  \"\"\"Discrete cosine transform\"\"\"\n",
    "  out = F.interpolate(x, size=(8, 8), mode='bilinear', align_corners=True)\n",
    "  dct_values_1 = [cv2.dct(np.float32(out[i, 0, :, :].detach().cpu().numpy())) for i in range(x.shape[0])]\n",
    "  dct_values_2 = [cv2.dct(np.float32(out[i, 1, :, :].detach().cpu().numpy())) for i in range(x.shape[0])]\n",
    "  dct_values_3 = [cv2.dct(np.float32(out[i, 2, :, :].detach().cpu().numpy())) for i in range(x.shape[0])]\n",
    "  dct_array_1 = np.array(dct_values_1)\n",
    "  dct_array_2 = np.array(dct_values_2)\n",
    "  dct_array_3 = np.array(dct_values_3)\n",
    "  dct_out_1 = torch.Tensor(dct_array_1)\n",
    "  dct_out_2 = torch.Tensor(dct_array_2)\n",
    "  dct_out_3 = torch.Tensor(dct_array_3)\n",
    "  dct_out = torch.zeros(size=(x.shape[0], 3, 8, 8))\n",
    "  dct_out[:, 0, :, :] = dct_out_1\n",
    "  dct_out[:, 1, :, :] = dct_out_2\n",
    "  dct_out[:, 2, :, :] = dct_out_3\n",
    "  dct_out = dct_out.cuda()\n",
    "  out = dct_out.view(x.shape[0], 3, 64)\n",
    "  out = F.glu(out, dim=-1)\n",
    "  dct_out = out.view(x.shape[0], 1, 96)\n",
    "  return dct_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PbQa8XjkpCJ3"
   },
   "outputs": [],
   "source": [
    "class SpectroChangeNet(nn.Module):\n",
    "    \"\"\"SpectroChangeNet\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SpectroChangeNet, self).__init__()\n",
    "        self.mrc1=MRC(3)\n",
    "        self.mrc2=MRC(5)\n",
    "        self.mrc3=MRC(5)\n",
    "        self.mrc4=MRC(5)\n",
    "        self.linear1=nn.Linear(341, 10)\n",
    "        self.linear2=nn.Linear(10, 2)\n",
    "    def forward(self, x):\n",
    "        m_1=self.mrc1(x)\n",
    "        m_2=self.mrc2(m_1)\n",
    "        m_3=self.mrc3(m_2)\n",
    "        m_4=self.mrc4(m_3)\n",
    "        glo=m_4.view(x.shape[0], 1, 245)\n",
    "        dct_out=DCT(x)\n",
    "        out=torch.cat((glo,dct_out),2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out_1 = self.linear1(out)\n",
    "        out = self.linear2(out_1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(torch.nn.Module):\n",
    "    \"\"\"Hybrid loss (focal_loss and mean absolute error)\"\"\"\n",
    "    def __init__(self, alpha=0.1, beta=0.9, gamma=2.0, classes=2):\n",
    "        super(Loss, self).__init__()\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma \n",
    "        self.classes = classes\n",
    "    def focal_loss(self, pred, labels):\n",
    "        pred = F.softmax(pred, dim=1)  \n",
    "        label_one_hot = torch.nn.functional.one_hot(labels, self.classes).float().to(self.device)\n",
    "        pt = torch.sum(pred * label_one_hot, dim=1)\n",
    "        focal_loss = -((1 - pt) ** self.gamma) * torch.log(pt + 1e-7)\n",
    "        return focal_loss.mean()\n",
    "    def forward(self, pred, labels):\n",
    "        fl = self.focal_loss(pred, labels)\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        label_one_hot = torch.nn.functional.one_hot(labels, self.classes).float().to(self.device)\n",
    "        mae = 2 - 2 * (torch.sum(pred * label_one_hot, dim=1))\n",
    "        loss = self.alpha * fl + self.beta * mae.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30237,
     "status": "ok",
     "timestamp": 1725282267578,
     "user": {
      "displayName": "ranjit",
      "userId": "17094336444566430795"
     },
     "user_tz": -330
    },
    "id": "RbqE0M5W3cZO",
    "outputId": "6a83ec02-b669-47cf-856f-adfece4461df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1]  [loss avg: 19.7618]  [current loss: 0.0000]\n",
      "[Epoch: 2]  [loss avg: 9.8869]  [current loss: 0.0000]\n",
      "[Epoch: 3]  [loss avg: 6.5917]  [current loss: 0.0000]\n",
      "[Epoch: 4]  [loss avg: 4.9440]  [current loss: 0.0000]\n",
      "[Epoch: 5]  [loss avg: 3.9554]  [current loss: 0.0000]\n",
      "[Epoch: 6]  [loss avg: 3.2963]  [current loss: 0.0000]\n",
      "[Epoch: 7]  [loss avg: 2.8255]  [current loss: 0.0000]\n",
      "[Epoch: 8]  [loss avg: 2.4724]  [current loss: 0.0000]\n",
      "[Epoch: 9]  [loss avg: 2.1977]  [current loss: 0.0000]\n",
      "[Epoch: 10]  [loss avg: 1.9780]  [current loss: 0.0000]\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"\"\"Model training\"\"\"\n",
    "istrain = True  \n",
    "net = SpectroChangeNet().to(device)\n",
    "criterion = Loss(alpha=0.1, beta=0.9, gamma=2.0, classes=2).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "net.train()\n",
    "total_loss = 0\n",
    "for epoch in range(10):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print('[Epoch: %d]  [loss avg: %.4f]  [current loss: %.4f]' % (epoch + 1, total_loss / (epoch + 1), loss.item()))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 420676,
     "status": "ok",
     "timestamp": 1725282688243,
     "user": {
      "displayName": "ranjit",
      "userId": "17094336444566430795"
     },
     "user_tz": -330
    },
    "id": "H4OujwlXq47L",
    "outputId": "637febe7-6362-4d9c-8215-9210dd0ae72f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranjit\\AppData\\Local\\Temp\\ipykernel_15716\\2517674177.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  outputs[i, j] = prediction+1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 50 handling\n",
      "row 100 handling\n",
      "row 150 handling\n",
      "row 200 handling\n",
      "row 250 handling\n",
      "row 300 handling\n",
      "row 350 handling\n"
     ]
    }
   ],
   "source": [
    "istrain=False \n",
    "\"\"\"Model testing\"\"\"\n",
    "net.eval()\n",
    "outputs = np.zeros((ylen, xlen))\n",
    "glo_fin=torch.Tensor([]).cuda()\n",
    "dct_fin=torch.Tensor([]).cuda()\n",
    "for i in range(ylen):\n",
    "    for j in range(xlen):\n",
    "        if preclassify_lab[i, j] != 1.5 :\n",
    "            outputs[i, j] = preclassify_lab[i, j]\n",
    "        else:\n",
    "            img_patch = x_test[i*xlen+j, :, :, :]\n",
    "            img_patch = img_patch.reshape(1, img_patch.shape[0], img_patch.shape[1], img_patch.shape[2])\n",
    "            img_patch = torch.FloatTensor(img_patch).to(device)\n",
    "            prediction = net(img_patch)\n",
    "            prediction = np.argmax(prediction.detach().cpu().numpy(), axis=1)\n",
    "            outputs[i, j] = prediction+1\n",
    "    if (i+1) % 50 == 0:\n",
    "        print('row', i+1, 'handling')\n",
    "outputs = outputs-1\n",
    "res = outputs*255\n",
    "res = postprocess(res)\n",
    "cv2.imwrite('Output_image.png',res)\n",
    "Output_image=cv2.imread('Output_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1725282688244,
     "user": {
      "displayName": "ranjit",
      "userId": "17094336444566430795"
     },
     "user_tz": -330
    },
    "id": "T8pjHeQa1VlU",
    "outputId": "3a8c4cbc-4a2c-4562-a35a-87ea80e59f3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Image overlaying\"\"\"\n",
    "_, binary_mask = cv2.threshold(Output_image, 200, 255, cv2.THRESH_BINARY)\n",
    "green_mask = np.zeros_like(image1)\n",
    "indices = np.where(binary_mask == 255)\n",
    "green_mask[indices[0], indices[1], :] = [0, 255, 0]\n",
    "overlay = cv2.add(image1, green_mask)\n",
    "cv2.imwrite('Overlay_image.png', overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
